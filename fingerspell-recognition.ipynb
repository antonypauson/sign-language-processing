{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8208775,"sourceType":"datasetVersion","datasetId":4864341}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential\nfrom tensorflow import data as tf_data\nfrom keras.layers import Dense, Dropout, GlobalAveragePooling1D, Input","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-02T01:31:07.417293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def parse_dataset():\n    train_points = []\n    train_labels = []\n    class_map = {}\n    folders = glob.glob(\"/kaggle/input/sign-points/dataset/\")\n    \n    letters = \"ABCDEFGHIKLMNOPQRSTUVWXY\"\n    \n    for i, letter in enumerate(letters):\n        print(f\"Processing class: {letter} {i}\")\n        \n        train_directory = f\"/kaggle/input/sign-points/dataset/{letter}\"\n        \n        class_map[i] = letter\n        train_files = glob.glob(train_directory + \"/*\")\n        \n        for train_file in train_files:\n            train_points.append(np.load(train_file))\n            train_labels.append(i)\n            \n        print(len(train_points))\n        print(len(train_labels))\n\n    return (\n        np.array(train_points),\n        np.array(train_labels),\n        class_map,\n    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_CLASSES = 24\nBATCH_SIZE = 64\n\ntrain_points, train_labels, CLASS_MAP = parse_dataset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_size = 0.8\ndataset = tf_data.Dataset.from_tensor_slices((train_points, train_labels))\ntrain_dataset_size = int(len(dataset) * train_size)\n\ndataset = dataset.shuffle(len(train_points))\n\ntrain_dataset = dataset.take(train_dataset_size).batch(BATCH_SIZE)\nvalidation_dataset = dataset.skip(train_dataset_size).batch(BATCH_SIZE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input layer\ninputs = keras.Input(shape=(21, 3))\nx = Dense(128, activation='relu')(inputs)\n\n# Hidden layers\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.5)(x)\nx = GlobalAveragePooling1D()(x)\n\n# Output layer for 26 ASL alphabets\noutputs = Dense(NUM_CLASSES, activation='softmax')(x)\nmodel = keras.Model(inputs=inputs, outputs=outputs, name=\"SLR\")\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(), loss=\"sparse_categorical_crossentropy\", metrics=[\"sparse_categorical_accuracy\"])\nhistory = model.fit(train_dataset, epochs=100, validation_data=validation_dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save(\"model.keras\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Extracting the history of training and validation accuracy and loss\nacc = history.history['sparse_categorical_accuracy']\nval_acc = history.history['val_sparse_categorical_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(acc) + 1)\n\n# Creating plots\nplt.style.use('seaborn-whitegrid') # Use a modern style\ncolors = ['#377eb8', '#ff7f00']  # A set of colors: blue and orange\nlinestyles = ['-', '--']  # Solid and dashed lines\n\nfig = plt.figure(figsize=(12, 6))\nfig.patch.set_facecolor('#f7f7f7')\n\n# Plotting training and validation accuracy\nplt.subplot(1, 2, 1)\nplt.title('Training and Validation Accuracy', fontsize=20)\nplt.plot(epochs, acc, 'r', label='Training Accuracy', linestyle=linestyles[0], color=colors[0], linewidth=2)\nplt.plot(epochs, val_acc, 'b', label=\"Validation Accuracy\", linestyle=linestyles[1], color=colors[1], linewidth=2)\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(loc='best')\nplt.grid(True, linestyle='--', linewidth=0.2)\n\n# Plotting training and validation loss\nplt.subplot(1, 2, 2)\nplt.title('Training and Validation Loss', fontsize=20)\nplt.plot(epochs, loss, 'r', label='Training Loss', linestyle=linestyles[0], color=colors[0], linewidth=2)\nplt.plot(epochs, val_loss, 'b', label=\"Validation Loss\", linestyle=linestyles[1], color=colors[1], linewidth=2)\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(loc='best')\nplt.grid(True, linestyle='--', linewidth=0.2)\n\nplt.savefig(\"training-and-validation-accuracy-and-loss.png\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}